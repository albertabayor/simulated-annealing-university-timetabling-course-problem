# Optimized Performance Plan for Timetable Constraint Checking

> **REVISED**: Based on actual profiling results from `profile-performance.ts`
>
> **Date**: 2026-01-01
> **Dataset**: 373 classes, 33 rooms, 99 lecturers
> **Current Runtime**: ~10.7 ms per iteration (215 seconds for 20K iterations)

---

## ğŸ“‹ Executive Summary

### ğŸ¯ Goal
Reduce optimization runtime by **50-60%** through a combination of quick fixes and strategic parallel processing, prioritized by actual profiling data.

### ğŸ“Š Current Performance (from profiling)

| Metric | Value | % of Total |
|--------|-------|------------|
| **Avg per iteration** | 10.7 ms | 100% |
| **Constraint Evaluation** | 7.7 ms | **36.0%** ğŸ”´ |
| **Hard Constraint Count (redundant)** | 4.0 ms | **18.4%** âš ï¸ |
| **Move Generation** | 7.5 ms | **34.6%** ğŸ”´ |
| **Other/Overhead** | 2.2 ms | 10.3% |
| **State Cloning** | 0.1 ms | 0.5% âœ… |

### ğŸš€ Optimization Roadmap

```
Phase 0: Quick Fixes          â†’ +28% speedup (2 hours)     âš¡ FREE
Phase 1: Parallel Top 3       â†’ +20% speedup (1 day)       ğŸš€ HIGH ROI
Phase 2: Investigate Slowest  â†’ +10% speedup (0.5 day)     ğŸ” MEDIUM
Phase 3: Parallel Soft Const. â†’ +5% speedup (1 day)        ğŸ“ˆ LOW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL                         â†’ +63% speedup (3.5 days)
```

**Final Target**: 10.7 ms â†’ **4.0 ms per iteration** (215s â†’ **80s for 20K iterations**)

---

## ğŸ”¬ Phase 0: Quick Fixes (HIGHEST ROI)

**Time**: 2 hours | **Expected Speedup**: +28% | **Priority**: ğŸ”´ CRITICAL

### Fix 1: Eliminate Redundant Constraint Evaluation (+18%)

**Problem Found**:
```
Constraint Evaluation:   7,737 ms (36.0%)
Hard Constraint Count:   3,978 ms (18.4%)  â† REDUNDANT!
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Waste:            3,978 ms (18.4% of total time!)
```

**Root Cause**:
- `calculateFitness()` evaluates ALL constraints (including hard)
- `countHardViolations()` evaluates hard constraints AGAIN
- This happens EVERY iteration (20,000 times!)

**Solution**:
```typescript
// src/core/SimulatedAnnealing.ts

// BEFORE (line 514-537)
private calculateFitness(state: TState): number {
  let hardPenalty = 0;
  let softPenalty = 0;

  for (const constraint of this.hardConstraints) {
    const score = constraint.evaluate(state);
    if (score < 1) {
      hardPenalty += (1 - score);
    }
  }

  for (const constraint of this.softConstraints) {
    const score = constraint.evaluate(state);
    if (score < 1) {
      softPenalty += (1 - score) * (constraint.weight ?? 10);
    }
  }

  return hardPenalty * this.config.hardConstraintWeight + softPenalty;
}

// AFTER (unified evaluation)
interface FitnessResult {
  fitness: number;
  hardViolations: number;
}

private calculateFitness(state: TState): FitnessResult {
  let hardPenalty = 0;
  let softPenalty = 0;
  let hardViolationCount = 0;  // â† Track once!

  // Evaluate hard constraints
  for (const constraint of this.hardConstraints) {
    const score = constraint.evaluate(state);
    if (score < 1) {
      hardPenalty += (1 - score);

      // Count violations HERE (not in separate function)
      if (constraint.getViolations) {
        hardViolationCount += constraint.getViolations(state).length;
      } else {
        hardViolationCount += Math.max(1, Math.round((1 / score) - 1));
      }
    }
  }

  // Evaluate soft constraints
  for (const constraint of this.softConstraints) {
    const score = constraint.evaluate(state);
    if (score < 1) {
      softPenalty += (1 - score) * (constraint.weight ?? 10);
    }
  }

  return {
    fitness: hardPenalty * this.config.hardConstraintWeight + softPenalty,
    hardViolations: hardViolationCount  // â† Return both
  };
}

// Remove or simplify countHardViolations()
// It's now redundant with calculateFitness()
```

**Files to Modify**:
- `src/core/SimulatedAnnealing.ts` (lines 514-564)
- Update all call sites of `calculateFitness()` and `countHardViolations()`

**Expected Impact**:
- Save ~4 ms per iteration (18.4%)
- 20K iterations: save **~80 seconds**

---

### Fix 2: Optimize Fix Lecturer Conflict Operator (+10%)

**Problem Found**:
```
Per-Operator Breakdown (from profiling):
Fix Lecturer Conflict:  852.8 ms / 237 calls = 3.6 ms per call
Average operator:       ~0.5 ms per call
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3.6 ms is 7x SLOWER than average!
```

**Investigation Needed**:
```typescript
// examples/timetabling/moves/FixLecturerConflict.ts

// Check why this is so slow:
// 1. Is it using inefficient constraint checking?
// 2. Is it doing unnecessary work?
// 3. Can we cache constraint violation lists?
```

**Solution Approach**:
1. Profile the operator itself to find bottleneck
2. Consider caching lecturer conflict lists
3. Optimize conflict detection logic

**Expected Impact**:
- Save ~1 ms per iteration (10%)
- 20K iterations: save **~20 seconds**

---

## ğŸš€ Phase 1: Parallelize Top 3 Constraints

**Time**: 1 day | **Expected Speedup**: +20% | **Priority**: ğŸ”´ HIGH

### Priority Based on Actual Profiling Data

| Constraint | Time (ms) | % Total | Parallel Potential | Priority |
|------------|-----------|---------|-------------------|----------|
| **No Prodi Conflict** | 0.38 | 9.7% | ğŸŸ¢ HIGH - Independent groups | **P0** |
| **No Lecturer Conflict** | 0.29 | 7.5% | ğŸŸ¢ HIGH - Independent groups | **P0** |
| **No Room Conflict** | 0.20 | 5.2% | ğŸŸ¢ HIGH - Independent groups | **P1** |
| **Compactness** | 0.23 | 5.9% | ğŸŸ¡ MEDIUM - Per prodi | P2 |
| **Transit Time** | 0.21 | 5.4% | ğŸŸ¡ MEDIUM - Per lecturer | P2 |
| **Preferred Time** | 1.09 | 28.3% | ğŸ” INVESTIGATE FIRST | P3 |

**Note**: `Preferred Time` is 28.3% of constraint time but may have different optimization needs.

---

### Implementation: Parallel by Data Groups

**Strategy**: Process constraint groups in parallel (e.g., different rooms, different lecturers)

```typescript
// examples/timetabling/constraints/hard/NoProdiConflict.ts

export class NoProdiConflict implements Constraint<TimetableState> {
  name = 'No Prodi Conflict';
  type = 'hard' as const;

  // NEW: Parallel evaluation method
  async evaluateParallel(
    state: TimetableState,
    executor: ParallelExecutor
  ): Promise<number> {

    const { schedule } = state;

    // Group by prodi + day - O(N)
    const grouped = groupScheduleByKey(schedule, (entry) =>
      `${entry.prodi}_${entry.timeSlot.day}`
    );

    // Process each group in parallel
    const results = await executor.execute(
      Array.from(grouped.values()),
      async (entries) => {
        return this.checkGroupConflicts(entries);
      }
    );

    // Sum violations from all groups
    const totalViolations = results.reduce((sum, count) => sum + count, 0);

    if (totalViolations === 0) return 1;
    return 1 / (1 + totalViolations);
  }

  // Extracted group checking logic (existing algorithm)
  private checkGroupConflicts(entries: ScheduleEntry[]): number {
    if (entries.length < 2) return 0;

    sortEntriesByStartTime(entries);
    let violationCount = 0;

    for (let i = 0; i < entries.length; i++) {
      const entry1 = entries[i];
      const end1 = getEndTimeInMinutes(entry1);

      for (let j = i + 1; j < entries.length; j++) {
        const entry2 = entries[j];
        const start2 = timeToMinutes(entry2.timeSlot.startTime);

        if (startsAfterEnd(end1, start2)) break;

        if (hasClassOverlap(entry1.class, entry2.class)) {
          violationCount++;
        }
      }
    }

    return violationCount;
  }

  // Keep original sequential method for fallback
  evaluate(state: TimetableState): number {
    // ... existing implementation ...
  }
}
```

**Expected Performance** (with 4 workers):

| Constraint | Sequential | Parallel (4 workers) | Speedup |
|------------|-----------|---------------------|---------|
| No Prodi Conflict | 0.38 ms | 0.12 ms | **3.2x** |
| No Lecturer Conflict | 0.29 ms | 0.10 ms | **2.9x** |
| No Room Conflict | 0.20 ms | 0.07 ms | **2.8x** |
| **Total Savings** | **0.87 ms** | **0.29 ms** | **~2 ms/iter** |

**Per iteration impact**: Save ~2 ms (20% total)
**For 20K iterations**: Save **~40 seconds**

---

### Parallel Infrastructure (Simplified for Bun)

Since you're using Bun, we can use a simpler approach:

```typescript
// src/utils/parallel/bun-parallel.ts

export interface ParallelExecutor {
  execute<T, R>(
    tasks: T[],
    handler: (task: T) => Promise<R> | R,
    concurrency?: number
  ): Promise<R[]>;
}

export class BunParallelExecutor implements ParallelExecutor {
  constructor(private concurrency: number = 4) {}

  async execute<T, R>(
    tasks: T[],
    handler: (task: T) => Promise<R> | R
  ): Promise<R[]> {

    // Bun doesn't have worker_threads yet, use Promise.all with batching
    const results: R[] = [];
    const chunks = this.chunkArray(tasks, this.concurrency);

    for (const chunk of chunks) {
      const chunkResults = await Promise.all(
        chunk.map(task => handler(task))
      );
      results.push(...chunkResults);
    }

    return results;
  }

  private chunkArray<T>(array: T[], size: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += size) {
      chunks.push(array.slice(i, i + size));
    }
    return chunks;
  }
}
```

**Files to Create**:
- `src/utils/parallel/bun-parallel.ts` (50 lines)

**Files to Modify**:
- `examples/timetabling/constraints/hard/NoProdiConflict.ts`
- `examples/timetabling/constraints/hard/NoLecturerConflict.ts`
- `examples/timetabling/constraints/hard/NoRoomConflict.ts`

---

## ğŸ” Phase 2: Investigate PreferredTime Constraint

**Time**: 0.5 day | **Expected Speedup**: +10% | **Priority**: ğŸŸ¡ MEDIUM

### Problem: PreferredTime is 28.3% of Constraint Time

```
Preferred Time: 2,189 ms / 2,000 calls = 1.09 ms per call
This is 3-5x SLOWER than other constraints!
```

### Investigation Steps

1. **Profile PreferredTime.evaluate()** to find bottleneck
2. **Check if it's O(nÂ²) or O(n log n)**
3. **Look for redundant computations**
4. **Consider caching preferred time slots**

### Possible Optimizations

```typescript
// examples/timetabling/constraints/soft/PreferredTime.ts

export class PreferredTime implements Constraint<TimetableState> {
  // Add cache for lecturer preferred slots
  private lecturerPreferredCache = new Map<string, TimeSlot[]>();

  evaluate(state: TimetableState): number {
    const { schedule } = state;
    let violationCount = 0;

    for (const entry of schedule) {
      // Check if lecturer has preferred time
      const lecturer = entry.lecturers[0]; // Assuming single lecturer
      const preferredSlots = this.getCachedPreferredSlots(lecturer);

      if (!this.isInPreferredTime(entry.timeSlot, preferredSlots)) {
        violationCount++;
      }
    }

    return 1 / (1 + violationCount);
  }

  private getCachedPreferredSlots(lecturer: string): TimeSlot[] {
    if (!this.lecturerPreferredCache.has(lecturer)) {
      // Compute and cache
      const slots = this.computePreferredSlots(lecturer);
      this.lecturerPreferredCache.set(lecturer, slots);
    }
    return this.lecturerPreferredCache.get(lecturer)!;
  }
}
```

**Expected Impact**:
- Save ~1 ms per iteration (10%)
- 20K iterations: save **~20 seconds**

---

## ğŸ“ˆ Phase 3: Parallelize Soft Constraints

**Time**: 1 day | **Expected Speedup**: +5% | **Priority**: ğŸŸ¢ LOW

After optimizing the top hard constraints and PreferredTime, parallelize remaining soft constraints:

| Constraint | Time (ms) | Parallel Potential |
|------------|-----------|-------------------|
| Compactness | 0.23 | ğŸŸ¢ HIGH - Per prodi |
| Transit Time | 0.21 | ğŸŸ¡ MEDIUM - Per lecturer |
| Prayer Time Overlap | 0.09 | ğŸŸ¢ HIGH - Independent checks |

**Expected Impact**:
- Save ~0.5 ms per iteration (5%)
- 20K iterations: save **~10 seconds**

---

## ğŸ“Š Expected Cumulative Performance

### Per Iteration Breakdown

| Phase | Optimization | Time Saved | Cumulative |
|-------|-------------|------------|------------|
| **Baseline** | Current | 0 ms | 10.7 ms |
| **Phase 0** | Redundant eval | -4.0 ms | 6.7 ms |
| **Phase 0** | Fix Lecturer op | -1.0 ms | 5.7 ms |
| **Phase 1** | Parallel top 3 | -2.0 ms | 3.7 ms |
| **Phase 2** | Optimize Preferred | -1.0 ms | 2.7 ms |
| **Phase 3** | Parallel soft | -0.5 ms | **2.2 ms** |

### Full Run Performance (20K iterations)

| Phase | Time (seconds) | Speedup |
|-------|---------------|---------|
| Baseline | 215 s | 1.0x |
| Phase 0 (2 hrs) | 135 s | **1.6x** |
| Phase 1 (+1 day) | 95 s | **2.3x** |
| Phase 2 (+0.5 day) | 80 s | **2.7x** |
| Phase 3 (+1 day) | 70 s | **3.1x** |

**Final Target**: **3x faster** (215s â†’ 70s) with **3.5 days total effort**

---

## ğŸ—ï¸ Implementation Plan

### Step 1: Phase 0 - Quick Fixes (2 hours)

```bash
git checkout -b feature/quick-performance-fixes
```

**Tasks**:
1. âœ… Modify `SimulatedAnnealing.calculateFitness()` to return `{ fitness, hardViolations }`
2. âœ… Remove redundant `countHardViolations()` calls
3. âœ… Update all call sites
4. âœ… Run profiler to validate (+18% speedup)
5. ğŸ” Profile `FixLecturerConflict` operator
6. âœ… Optimize based on findings (+10% speedup)

**Validation**:
```bash
bun run examples/timetabling/profile-performance.ts
# Expected: Avg per iteration ~7.7 ms (down from 10.7 ms)
```

---

### Step 2: Phase 1 - Parallel Top 3 (1 day)

```bash
git checkout -b feature/parallel-constraints
```

**Tasks**:
1. âœ… Create `src/utils/parallel/bun-parallel.ts`
2. âœ… Add `evaluateParallel()` to `NoProdiConflict`
3. âœ… Add `evaluateParallel()` to `NoLecturerConflict`
4. âœ… Add `evaluateParallel()` to `NoRoomConflict`
5. âœ… Integrate with `SimulatedAnnealing`
6. âœ… Benchmark and validate

**Validation**:
```bash
bun run examples/timetabling/profile-performance.ts
# Expected: Avg per iteration ~5.7 ms (down from 7.7 ms)
```

---

### Step 3: Phase 2 - Optimize PreferredTime (0.5 day)

**Tasks**:
1. ğŸ” Profile `PreferredTime.evaluate()` method
2. ğŸ” Identify bottleneck
3. âœ… Implement optimization (caching, algorithm, etc.)
4. âœ… Validate

**Validation**:
```bash
bun run examples/timetabling/profile-performance.ts
# Expected: Avg per iteration ~4.7 ms (down from 5.7 ms)
```

---

### Step 4: Phase 3 - Parallel Soft Constraints (1 day)

**Tasks**:
1. âœ… Add `evaluateParallel()` to `Compactness`
2. âœ… Add `evaluateParallel()` to `TransitTime`
3. âœ… Add `evaluateParallel()` to `PrayerTimeOverlap`
4. âœ… Integrate and validate

**Validation**:
```bash
bun run examples/timetabling/profile-performance.ts
# Expected: Avg per iteration ~4.2 ms (down from 4.7 ms)
```

---

### Step 5: Full Integration Test (0.5 day)

**Tasks**:
1. âœ… Run full optimization with `example-basic.ts`
2. âœ… Compare solution quality (should be identical)
3. âœ… Measure total runtime improvement
4. âœ… Document results

**Final Validation**:
```bash
bun run examples/timetabling/example-basic.ts
# Expected: Total runtime ~70-80 seconds (down from 215 seconds)
```

---

## ğŸ§ª Testing Strategy

### Performance Regression Tests

```typescript
// tests/performance/constraints.test.ts

describe('Constraint Performance', () => {
  it('should evaluate NoProdiConflict in < 0.15ms (parallel)', async () => {
    const state = createTestState();
    const constraint = new NoProdiConflict();
    const executor = new BunParallelExecutor(4);

    const start = performance.now();
    await constraint.evaluateParallel(state, executor);
    const time = performance.now() - start;

    expect(time).toBeLessThan(0.15);
  });

  it('should be faster than sequential', async () => {
    const state = createTestState();
    const constraint = new NoProdiConflict();
    const executor = new BunParallelExecutor(4);

    // Sequential
    const seqStart = performance.now();
    constraint.evaluate(state);
    const seqTime = performance.now() - seqStart;

    // Parallel
    const parStart = performance.now();
    await constraint.evaluateParallel(state, executor);
    const parTime = performance.now() - parStart;

    expect(parTime).toBeLessThan(seqTime * 0.5); // At least 2x faster
  });
});
```

### Correctness Validation

```typescript
describe('Parallel Correctness', () => {
  it('should produce same results as sequential', async () => {
    const state = createTestState();
    const constraint = new NoProdiConflict();
    const executor = new BunParallelExecutor(4);

    const sequentialScore = constraint.evaluate(state);
    const parallelScore = await constraint.evaluateParallel(state, executor);

    expect(parallelScore).toBeCloseTo(sequentialScore, 6);
  });
});
```

---

## âš ï¸ Risks & Mitigations

### Risk 1: Parallel Overhead > Benefits

**Mitigation**:
- Only parallelize constraints with > 0.2 ms per call
- Set minimum group size threshold
- Benchmark before/after each optimization

### Risk 2: Bun's Promise.all is Not True Parallelism

**Mitigation**:
- Bun uses cooperative multitasking, not pre-emptive
- For CPU-bound tasks, speedup may be less than expected
- Consider using Bun's experimental `worker` module if needed

### Risk 3: Solution Quality Regression

**Mitigation**:
- Extensive correctness tests
- Compare solution quality before/after
- Use deterministic random seed for testing

---

## ğŸ“š Implementation Checklist

### Phase 0: Quick Fixes (2 hours)
- [ ] Modify `calculateFitness()` to return `{ fitness, hardViolations }`
- [ ] Remove redundant `countHardViolations()` calls
- [ ] Update call sites in `SimulatedAnnealing.ts`
- [ ] Profile `FixLecturerConflict` operator
- [ ] Optimize based on findings
- [ ] Run profiler to validate (+28% expected)

### Phase 1: Parallel Top 3 (1 day)
- [ ] Create `src/utils/parallel/bun-parallel.ts`
- [ ] Add `evaluateParallel()` to `NoProdiConflict`
- [ ] Add `evaluateParallel()` to `NoLecturerConflict`
- [ ] Add `evaluateParallel()` to `NoRoomConflict`
- [ ] Integrate with `SimulatedAnnealing`
- [ ] Add performance tests
- [ ] Benchmark and validate (+20% expected)

### Phase 2: Optimize PreferredTime (0.5 day)
- [ ] Profile `PreferredTime.evaluate()`
- [ ] Identify bottleneck
- [ ] Implement optimization
- [ ] Validate (+10% expected)

### Phase 3: Parallel Soft Constraints (1 day)
- [ ] Add `evaluateParallel()` to `Compactness`
- [ ] Add `evaluateParallel()` to `TransitTime`
- [ ] Add `evaluateParallel()` to `PrayerTimeOverlap`
- [ ] Validate (+5% expected)

### Phase 4: Integration & Testing (0.5 day)
- [ ] Full integration test with `example-basic.ts`
- [ ] Compare solution quality
- [ ] Document results
- [ ] Update README

---

## ğŸ¯ Success Criteria

### Performance Targets

| Metric | Current | Target | Status |
|--------|---------|--------|--------|
| Avg per iteration | 10.7 ms | 4.2 ms | â³ Pending |
| Total runtime (20K) | 215 s | 80 s | â³ Pending |
| Speedup | 1.0x | 3.0x | â³ Pending |

### Quality Targets

| Metric | Target |
|--------|--------|
| Solution quality | No regression (Â±5%) |
| Test coverage | >90% |
| Performance tests | All passing |

---

## ğŸ“– References

### Profiling Results
- `examples/timetabling/profile-performance.ts` - Full profiling script
- Run with: `bun run examples/timetabling/profile-performance.ts`

### Related Files
- `src/core/SimulatedAnnealing.ts` - Main optimization loop
- `examples/timetabling/constraints/` - All constraint implementations
- `examples/timetabling/moves/` - Move generator implementations

---

## âœ… Next Steps

1. âœ… **Start with Phase 0** (Quick fixes - 2 hours, +28% speedup)
2. â³ Validate with profiler
3. â³ Proceed to Phase 1 (Parallel top 3)
4. â³ Continue based on results

**Recommended**: Implement Phase 0 first to validate the approach and get immediate wins before investing in parallel infrastructure.

---

**Status**: ğŸ“ Plan Revised Based on Profiling - Ready for Implementation

**Last Updated**: 2026-01-01

**Author**: Claude Code (inspired by profiling data)

**Total Estimated Effort**: 3.5 days for **3x speedup** (215s â†’ 70s)
